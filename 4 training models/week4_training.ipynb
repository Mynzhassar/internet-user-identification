{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 4.  Сравнение алгоритмов классификации\n",
    "\n",
    "Теперь мы наконец подойдем к обучению моделей классификации, сравним на кросс-валидации несколько алгоритмов, разберемся, какие параметры длины сессии (*session_length* и *window_size*) лучше использовать. Также для выбранного алгоритма построим кривые валидации (как качество классификации зависит от одного из гиперпараметров алгоритма) и кривые обучения (как качество классификации зависит от объема выборки).\n",
    "\n",
    "**План 4 недели:**\n",
    "- Часть 1. Сравнение нескольких алгоритмов на сессиях из 10 сайтов\n",
    "- Часть 2. Выбор параметров – длины сессии и ширины окна\n",
    "- Часть 3. Идентификация  конкретного пользователя и кривые обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.3\n",
      "IPython 7.6.1\n",
      "\n",
      "numpy 1.16.4\n",
      "scipy 1.2.1\n",
      "pandas 0.24.2\n",
      "matplotlib 3.1.0\n",
      "statsmodels 0.10.0\n",
      "sklearn 0.0\n",
      "\n",
      "compiler   : MSC v.1915 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 9c1c5e620352870d2b49f03c1d96024868c5206c\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = r'C:\\Users\\Диас\\Desktop\\DiaStudy\\internet user identification\\1 data preparation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Сравнение нескольких алгоритмов на сессиях из 10 сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим сериализованные ранее объекты *X_sparse_10users* и *y_10users*, соответствующие обучающей выборке для 10 пользователей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, \n",
    "         'X_sparse_10users.pkl'), 'rb') as X_sparse_10users_pkl:\n",
    "    X_sparse_10users = pickle.load(X_sparse_10users_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, \n",
    "                       'y_10users.pkl'), 'rb') as y_10users_pkl:\n",
    "    y_10users = pickle.load(y_10users_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Здесь более 14 тысяч сессий и почти 5 тысяч уникальных посещенных сайтов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14061, 4913)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse_10users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разобьем выборку на 2 части. На одной будем проводить кросс-валидацию, на второй – оценивать модель, обученную после кросс-валидации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_sparse_10users, y_10users, \n",
    "                                                      test_size=0.3, \n",
    "                                                     random_state=17, stratify=y_10users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Зададим заранее тип кросс-валидации: 3-кратная, с перемешиванием, параметр random_state=17 – для воспроизводимости.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вспомогательная функция для отрисовки кривых валидации после запуска GridSearchCV (или RandomizedCV).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curves(param_values, grid_cv_results_):\n",
    "    train_mu, train_std = grid_cv_results_['mean_train_score'], grid_cv_results_['std_train_score']\n",
    "    valid_mu, valid_std = grid_cv_results_['mean_test_score'], grid_cv_results_['std_test_score']\n",
    "    train_line = plt.plot(param_values, train_mu, '-', label='train', color='green')\n",
    "    valid_line = plt.plot(param_values, valid_mu, '-', label='test', color='red')\n",
    "    plt.fill_between(param_values, train_mu - train_std, train_mu + train_std, edgecolor='none',\n",
    "                     facecolor=train_line[0].get_color(), alpha=0.2)\n",
    "    plt.fill_between(param_values, valid_mu - valid_std, valid_mu + valid_std, edgecolor='none',\n",
    "                     facecolor=valid_line[0].get_color(), alpha=0.2)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Обучите `KNeighborsClassifier` со 100 ближайшими соседями (остальные параметры оставьте по умолчанию, только `n_jobs`=-1 для распараллеливания) и посмотрите на долю правильных ответов на 3-кратной кросс-валидации (ради воспроизводимости используйте для этого объект `StratifiedKFold` `skf`) по выборке `(X_train, y_train)` и отдельно на выборке `(X_valid, y_valid)`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=100, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred_split = knn_model.fit(X_train, y_train).predict(X_valid)\n",
    "knn_score_split = accuracy_score(y_valid, knn_pred_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_score_cv = cross_val_score(knn_model, X_train, y_train, cv=skf).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 1. </font> Посчитайте доли правильных ответов для KNeighborsClassifier на кросс-валидации и отложенной выборке. Округлите каждое до 3 знаков после запятой и введите через пробел.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer4_1.txt\", 'w') as fout:\n",
    "    fout.write(f'{knn_score_cv:.3f} {knn_score_split:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Обучите случайный лес (`RandomForestClassifier`) из 100 деревьев (для воспроизводимости `random_state`=17). Посмотрите на OOB-оценку (для этого надо сразу установить `oob_score`=True) и на долю правильных ответов на выборке `(X_valid, y_valid)`. Для распараллеливания задайте `n_jobs`=-1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 2. </font> Посчитайте доли правильных ответов для `RandomForestClassifier` при Out-of-Bag оценке и на отложенной выборке. Округлите каждое до 3 знаков после запятой и введите через пробел.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predict_split = rf_model.fit(X_train, y_train).predict(X_valid)\n",
    "rf_score_split = accuracy_score(y_valid, rf_predict_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_score_cv = np.mean(cross_val_score(rf_model, X_train, y_train, cv=skf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer4_2.txt\", 'w') as fout:\n",
    "    fout.write(f'{rf_score_cv:.3f} {rf_score_split:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Обучите логистическую регрессию (`LogisticRegression`) с параметром `C` по умолчанию и `random_state`=17 (для воспроизводимости). Посмотрите на долю правильных ответов на кросс-валидации (используйте объект `skf`, созданный ранее) и на выборке `(X_valid, y_valid)`. Для распараллеливания задайте `n_jobs=-1`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "logit = LogisticRegression(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_score_cv = np.mean(cross_val_score(logit, X_train, y_train, cv=skf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Почитайте документацию к [LogisticRegressionCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html). Логистическая регрессия хорошо изучена, и для нее существуют алгоритмы быстрого подбора параметра регуляризации `C` (быстрее, чем с `GridSearchCV`).**\n",
    "\n",
    "**С помощью `LogisticRegressionCV` подберите параметр `C` для `LogisticRegression` сначала в широком диапазоне: 10 значений от 1e-4 до 1e2, используйте `logspace` из `NumPy`. Укажите у `LogisticRegressionCV` параметры `multi_class`='multinomial' и `random_state`=17. Для кросс-валидации используйте объект `skf`, созданный ранее. Для распараллеливания задайте `n_jobs=-1`.**\n",
    "\n",
    "**Нарисуйте кривые валидации по параметру `C`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=17),\n",
       "             param_grid={'C': array([1.00023029e+000, 1.29181404e+011, 1.66839930e+022, 2.15476543e+033,\n",
       "       2.78291537e+044, 3.59418146e+055, 4.64194510e+066, 5.99514926e+077,\n",
       "       7.74283492e+088, 1.00000000e+100])})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logit_c_values1 = np.logspace(1e-4, 1e2, 10)\n",
    "\n",
    "logit_grid_searcher1 = GridSearchCV(logit, param_grid = {\"C\": logit_c_values1}, cv=skf)\n",
    "logit_grid_searcher1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите лучшее значение доли правильных ответов на кросс-валидации и соответствующее значение `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7607204451349604, {'C': 1.0002302850208247})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher1.best_score_, logit_grid_searcher1.best_params_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь то же самое, только значения параметра `C` перебирайте в диапазоне `np.linspace`(0.1, 7, 20). Опять нарисуйте кривые валидации, определите максимальное значение доли правильных ответов на кросс-валидации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "             estimator=LogisticRegression(random_state=17),\n",
       "             param_grid={'C': array([0.1       , 0.46315789, 0.82631579, 1.18947368, 1.55263158,\n",
       "       1.91578947, 2.27894737, 2.64210526, 3.00526316, 3.36842105,\n",
       "       3.73157895, 4.09473684, 4.45789474, 4.82105263, 5.18421053,\n",
       "       5.54736842, 5.91052632, 6.27368421, 6.63684211, 7.        ])})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logit_c_values2 = np.linspace(0.1, 7, 20)\n",
    "\n",
    "logit_grid_searcher2 = GridSearchCV(logit, param_grid = {\"C\": logit_c_values2}, cv=skf)\n",
    "logit_grid_searcher2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите лучшее значение доли правильных ответов на кросс-валидации и соответствующее значение `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7626511226252158, {'C': 1.9157894736842107})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher2.best_score_, logit_grid_searcher2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 3. </font>Посчитайте доли правильных ответов для `logit_grid_searcher2` на кросс-валидации для лучшего значения параметра `C` и на отложенной выборке. Округлите каждое до 3 знаков после запятой и выведите через пробел.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_score_cv = np.mean(cross_val_score(logit_grid_searcher2.best_estimator_, X_train, y_train, cv=skf))\n",
    "logit_score_split = accuracy_score(y_valid, logit_grid_searcher2.best_estimator_.fit(X_train, y_train).predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer4_3.txt\", 'w') as fout:\n",
    "    fout.write(f'{logit_score_cv:.3f} {logit_score_split:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Обучите линейный SVM (`LinearSVC`) с параметром `C`=1 и `random_state`=17 (для воспроизводимости). Посмотрите на долю правильных ответов на кросс-валидации (используйте объект `skf`, созданный ранее) и на выборке `(X_valid, y_valid)`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(C=1, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**С помощью `GridSearchCV` подберите параметр `C` для SVM сначала в широком диапазоне: 10 значений от 1e-4 до 1e4, используйте `linspace` из NumPy. Нарисуйте кривые валидации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "             estimator=LinearSVC(C=1, random_state=17),\n",
       "             param_grid={'C': array([1.0000000e-04, 1.1111112e+03, 2.2222223e+03, 3.3333334e+03,\n",
       "       4.4444445e+03, 5.5555556e+03, 6.6666667e+03, 7.7777778e+03,\n",
       "       8.8888889e+03, 1.0000000e+04])})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_params1 = {'C': np.linspace(1e-4, 1e4, 10)}\n",
    "\n",
    "svm_grid_searcher1 = GridSearchCV(svm, param_grid=svm_params1, cv=skf)\n",
    "svm_grid_searcher1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите лучшее значение доли правильных ответов на кросс-валидации и соответствующее значение `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.694880724942574, {'C': 8888.8889})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_searcher1.best_score_, svm_grid_searcher1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Но мы помним, что с параметром регуляризации по умолчанию (С=1) на кросс-валидации доля правильных ответов выше. Это тот случай (не редкий), когда можно ошибиться и перебирать параметры не в том диапазоне (причина в том, что мы взяли равномерную сетку на большом интервале и упустили действительно хороший интервал значений `C`). Здесь намного осмысленней подбирать `C` в районе 1, к тому же, так модель быстрее обучается, чем при больших `C`. **\n",
    "\n",
    "**С помощью `GridSearchCV` подберите параметр `C` для SVM в диапазоне (1e-3, 1), 30 значений, используйте `linspace` из NumPy. Нарисуйте кривые валидации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=17, shuffle=True),\n",
       "             estimator=LinearSVC(C=1, random_state=17),\n",
       "             param_grid={'C': array([0.001     , 0.03544828, 0.06989655, 0.10434483, 0.1387931 ,\n",
       "       0.17324138, 0.20768966, 0.24213793, 0.27658621, 0.31103448,\n",
       "       0.34548276, 0.37993103, 0.41437931, 0.44882759, 0.48327586,\n",
       "       0.51772414, 0.55217241, 0.58662069, 0.62106897, 0.65551724,\n",
       "       0.68996552, 0.72441379, 0.75886207, 0.79331034, 0.82775862,\n",
       "       0.8622069 , 0.89665517, 0.93110345, 0.96555172, 1.        ])})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_params2 = {'C': np.linspace(1e-3, 1, 30)}\n",
    "\n",
    "svm_grid_searcher2 = GridSearchCV(svm, param_grid=svm_params2, cv=skf)\n",
    "svm_grid_searcher2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите лучшее значение доли правильных ответов на кросс-валидации и соответствующее значение `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7674269259074791, {'C': 0.13879310344827586})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_searcher2.best_score_, svm_grid_searcher2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите долю правильных ответов на выборке `(X_valid, y_valid)` для `LinearSVC` с лучшим найденным значением `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 4. </font> Посчитайте доли правильных ответов для `svm_grid_searcher2` на кросс-валидации для лучшего значения параметра `C` и на отложенной выборке. Округлите каждое до 3 знаков после запятой и выведите через пробел.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_score_cv = np.mean(cross_val_score(svm_grid_searcher2.best_estimator_, X_train, y_train, cv=skf))\n",
    "svm_score_split = accuracy_score(y_valid, svm_grid_searcher2.best_estimator_.fit(X_train, y_train).predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer4_4.txt\", 'w') as fout:\n",
    "    fout.write(f'{svm_score_cv:.3f} {svm_score_split:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Выбор параметров – длины сессии и ширины окна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Возьмем `LinearSVC`, показавший лучшее качество на кросс-валидации в 1 части, и проверим его работу еще на 8 выборках для 10 пользователей (с разными сочетаниями параметров *session_length* и *window_size*). Поскольку тут уже вычислений побольше, мы не будем каждый раз заново подбирать параметр регуляризации `C`.**\n",
    "\n",
    "**Определите функцию `model_assessment`, ее документация описана ниже. Обратите внимание на все детали. Например, на то, что разбиение  выборки с `train_test_split` должно быть стратифицированным. Не теряйте нигде `random_state`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_assessment(estimator, path_to_X_pickle, path_to_y_pickle, cv, random_state=17, test_size=0.3):\n",
    "\n",
    "    with open(path_to_X_pickle, 'rb') as fx: X = pickle.load(fx)\n",
    "    with open(path_to_y_pickle, 'rb') as fy: y = pickle.load(fy)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                        random_state=random_state,\n",
    "                                                        stratify=y)\n",
    "    \n",
    "    estimator_score_cv = np.mean(cross_val_score(estimator, X_train, y_train, cv=cv))\n",
    "    estimator_score_split = accuracy_score(y_test, estimator.fit(X_train, y_train).predict(X_test))\n",
    "    \n",
    "    return estimator_score_cv, estimator_score_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Убедитесь, что функция работает.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7674269259074791, 0.7819388480682626)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_assessment(svm_grid_searcher2.best_estimator_, \n",
    "                 os.path.join(PATH_TO_DATA, 'X_sparse_10users.pkl'),\n",
    "        os.path.join(PATH_TO_DATA, 'y_10users.pkl'), skf, random_state=17, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените функцию *model_assessment* для лучшего алгоритма из предыдущей части (а именно, `svm_grid_searcher2.best_estimator_`) и 9 выборок вида с разными сочетаниями параметров *session_length* и *window_size* для 10 пользователей. Выведите в цикле параметры *session_length* и *window_size*, а также результат вывода функции *model_assessment*. \n",
    "Удобно сделать так, чтоб *model_assessment* возвращала 3-им элементом время, за которое она выполнилась. На моем ноуте этот участок кода выполнился за 20 секунд. Но со 150 пользователями каждая итерация занимает уже несколько минут.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь для удобства стоит создать копии ранее созданных pickle-файлов X_sparse_10users.pkl, X_sparse_150users.pkl, y_10users.pkl и y_150users.pkl, добавив к их названиям s10_w10, что означает длину сессии 10 и ширину окна 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA2 = r'C:\\Users\\Диас\\Desktop\\DiaStudy\\internet user identification\\2 hypotheses analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: window_size: 10, session_length: 15\n",
      "Scores: cv: 0.8146726161714527, split: 0.8328987911827447\n",
      "\n",
      "Parameters: window_size: 10, session_length: 10\n",
      "Scores: cv: 0.7674269259074791, split: 0.7819388480682626\n",
      "\n",
      "Parameters: window_size: 7, session_length: 15\n",
      "Scores: cv: 0.8416788984451413, split: 0.8450306952049113\n",
      "\n",
      "Parameters: window_size: 7, session_length: 10\n",
      "Scores: cv: 0.7865580836233855, split: 0.7904430064708811\n",
      "\n",
      "Parameters: window_size: 7, session_length: 7\n",
      "Scores: cv: 0.7347796199129073, split: 0.7449809191969471\n",
      "\n",
      "Parameters: window_size: 5, session_length: 15\n",
      "Scores: cv: 0.8591602044849895, split: 0.8694879089615932\n",
      "\n",
      "Parameters: window_size: 5, session_length: 10\n",
      "Scores: cv: 0.807285614179873, split: 0.8160265528686581\n",
      "\n",
      "Parameters: window_size: 5, session_length: 7\n",
      "Scores: cv: 0.7535308264033714, split: 0.7625651967757231\n",
      "\n",
      "Parameters: window_size: 5, session_length: 5\n",
      "Scores: cv: 0.7002335493176605, split: 0.7095779990516833\n",
      "\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = svm_grid_searcher2.best_estimator_\n",
    "\n",
    "for window_size, session_length in itertools.product([10, 7, 5], [15, 10, 7, 5]):\n",
    "    if window_size <= session_length:\n",
    "        path_to_X_pkl = os.path.join(PATH_TO_DATA2, f'X_sparse_10users_s{session_length}_w{window_size}.pkl')\n",
    "        path_to_y_pkl = os.path.join(PATH_TO_DATA2, f'y_10users_s{session_length}_w{window_size}.pkl')\n",
    "        \n",
    "        score_cv, score_split = model_assessment(estimator=svm_grid_searcher2.best_estimator_,\n",
    "                                                 path_to_X_pickle=path_to_X_pkl, \n",
    "                                                 path_to_y_pickle=path_to_y_pkl, \n",
    "                                                 cv=skf)\n",
    "        \n",
    "        print(f\"Parameters: window_size: {window_size}, session_length: {session_length}\")\n",
    "        print(f\"Scores: cv: {score_cv}, split: {score_split}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 5. </font> Посчитайте доли правильных ответов для `LinearSVC` с настроенным параметром `C` и выборки `X_sparse_10users_s15_w5`. Укажите доли правильных ответов на кросс-валидации и на отложенной выборке. Округлите каждое до 3 знаков после запятой и выведите через пробел.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_cv, score_split = model_assessment(estimator=svm_grid_searcher2.best_estimator_, \n",
    "                                         path_to_X_pickle=os.path.join(PATH_TO_DATA2, 'X_sparse_10users_s15_w5.pkl'),\n",
    "                                         path_to_y_pickle=os.path.join(PATH_TO_DATA2, 'y_10users_s15_w5.pkl'), \n",
    "                                         cv=skf, random_state=17, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer4_5.txt\", 'w') as fout:\n",
    "    fout.write(f'{score_cv:.3f} {score_split:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Прокомментируйте полученные результаты. Сравните для 150 пользователей доли правильных ответов на кросс-валидации и оставленной выборке для сочетаний параметров (*session_length, window_size*): (5,5), (7,7) и (10,10). На среднем ноуте это может занять до часа – запаситесь терпением, это Data Science :) **\n",
    "\n",
    "**Сделайте вывод о том, как качество классификации зависит от длины сессии и ширины окна.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: window_size: 5, session_length: 5\n",
      "Scores: cv: 0.3812138562541391, split: 0.3939261206015477\n",
      "\n",
      "Parameters: window_size: 7, session_length: 7\n",
      "Scores: cv: 0.41790391100600005, split: 0.4321115917839016\n",
      "\n",
      "Parameters: window_size: 10, session_length: 10\n",
      "Scores: cv: 0.4622105449730485, split: 0.48214372597674304\n",
      "\n",
      "Wall time: 23min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = svm_grid_searcher2.best_estimator_\n",
    "\n",
    "for window_size, session_length in [(5,5), (7,7), (10,10)]:\n",
    "    path_to_X_pkl = os.path.join(PATH_TO_DATA2, f'X_sparse_150users_s{session_length}_w{window_size}.pkl')\n",
    "    path_to_y_pkl = os.path.join(PATH_TO_DATA2, f'y_150users_s{session_length}_w{window_size}.pkl')\n",
    "        \n",
    "    score_cv, score_split = model_assessment(estimator=svm_grid_searcher2.best_estimator_,\n",
    "                                            path_to_X_pickle=path_to_X_pkl, \n",
    "                                            path_to_y_pickle=path_to_y_pkl, \n",
    "                                            cv=skf)\n",
    "        \n",
    "    print(f\"Parameters: window_size: {window_size}, session_length: {session_length}\")\n",
    "    print(f\"Scores: cv: {score_cv}, split: {score_split}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 6. </font> Посчитайте доли правильных ответов для `LinearSVC` с настроенным параметром `C` и выборки `X_sparse_150users`. Укажите доли правильных ответов на кросс-валидации и на отложенной выборке. Округлите каждое до 3 знаков после запятой и выведите через пробел.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_cv, score_split = model_assessment(estimator=svm_grid_searcher2.best_estimator_, \n",
    "                                         path_to_X_pickle=os.path.join(PATH_TO_DATA, 'X_sparse_150users.pkl'),\n",
    "                                         path_to_y_pickle=os.path.join(PATH_TO_DATA, 'y_150users.pkl'), \n",
    "                                         cv=skf, random_state=17, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"answer4_6.txt\", 'w') as fout:\n",
    "    fout.write(f'{score_cv:.3f} {score_split:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Идентификация  конкретного пользователя и кривые обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поскольку может разочаровать, что многоклассовая доля правильных ответов на выборке из 150 пользовалей невелика, порадуемся тому, что конкретного пользователя можно идентифицировать достаточно хорошо. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим сериализованные ранее объекты *X_sparse_150users* и *y_150users*, соответствующие обучающей выборке для 150 пользователей с параметрами (*session_length, window_size*) = (10,10). Так же точно разобьем их на 70% и 30%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'X_sparse_150users.pkl'), 'rb') as X_sparse_150users_pkl:\n",
    "     X_sparse_150users = pickle.load(X_sparse_150users_pkl)\n",
    "with open(os.path.join(PATH_TO_DATA, 'y_150users.pkl'), 'rb') as y_150users_pkl:\n",
    "    y_150users = pickle.load(y_150users_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_150, X_valid_150, y_train_150, y_valid_150 = train_test_split(X_sparse_150users, \n",
    "                                                                      y_150users, test_size=0.3, \n",
    "                                                     random_state=17, stratify=y_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите `LogisticRegressionCV` для одного значения параметра `C` (лучшего на кросс-валидации в 1 части, используйте точное значение, не на глаз). Теперь будем решать 150 задач \"Один-против-Всех\", поэтому укажите аргумент `multi_class`='ovr'. Как всегда, где возможно, указывайте `n_jobs=-1` и `random_state`=17.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = [logit_grid_searcher2.best_params_['C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[1.9157894736842107], multi_class='ovr', n_jobs=-1,\n",
       "                     random_state=17)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_cv_150users = LogisticRegressionCV(Cs=best_param, multi_class='ovr', \n",
    "                                         n_jobs=-1, random_state=17, cv=skf)\n",
    "logit_cv_150users.fit(X_train_150, y_train_150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрите на средние доли правильных ответов на кросс-валидации в задаче идентификации каждого пользователя по отдельности.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1, CV score: 0.9961006282970469\n",
      "User 2, CV score: 0.9964134150184119\n",
      "User 3, CV score: 0.9953395312258225\n",
      "User 4, CV score: 0.992076167016406\n",
      "User 5, CV score: 0.9903558400488981\n",
      "User 6, CV score: 0.9943177687700093\n",
      "User 7, CV score: 0.993848591949112\n",
      "User 8, CV score: 0.986081132215773\n",
      "User 9, CV score: 0.9980190364547321\n",
      "User 10, CV score: 0.9952665515708844\n",
      "User 11, CV score: 0.9946097020649383\n",
      "User 12, CV score: 0.9937756144682744\n",
      "User 13, CV score: 0.9968930193678147\n",
      "User 14, CV score: 0.994745236563934\n",
      "User 15, CV score: 0.9963300034867677\n",
      "User 16, CV score: 0.9963612877028598\n",
      "User 17, CV score: 0.9907207589775409\n",
      "User 18, CV score: 0.9944324569083948\n",
      "User 19, CV score: 0.9946096993473128\n",
      "User 20, CV score: 0.9914401660451702\n",
      "User 21, CV score: 0.9807742365724291\n",
      "User 22, CV score: 0.9968825940134094\n",
      "User 23, CV score: 0.9948390669276825\n",
      "User 24, CV score: 0.9910752427683269\n",
      "User 25, CV score: 0.9966323670278276\n",
      "User 26, CV score: 0.9942760640912371\n",
      "User 27, CV score: 0.99519356050192\n",
      "User 28, CV score: 0.9916278191633168\n",
      "User 29, CV score: 0.9849655508102375\n",
      "User 30, CV score: 0.997247503158601\n",
      "User 31, CV score: 0.9971223934704854\n",
      "User 32, CV score: 0.9968513114278924\n",
      "User 33, CV score: 0.9973309201254958\n",
      "User 34, CV score: 0.9965698132708202\n",
      "User 35, CV score: 0.9969764270947834\n",
      "User 36, CV score: 0.9976541251354403\n",
      "User 37, CV score: 0.9875824941292635\n",
      "User 38, CV score: 0.9965281058744229\n",
      "User 39, CV score: 0.9963612855287597\n",
      "User 40, CV score: 0.9966323643102022\n",
      "User 41, CV score: 0.9903558476582491\n",
      "User 42, CV score: 0.988937889123527\n",
      "User 43, CV score: 0.9962778767147409\n",
      "User 44, CV score: 0.995819125791774\n",
      "User 45, CV score: 0.9960172227441785\n",
      "User 46, CV score: 0.9950997252464455\n",
      "User 47, CV score: 0.9960693544079311\n",
      "User 48, CV score: 0.996976422203058\n",
      "User 49, CV score: 0.9950163191500521\n",
      "User 50, CV score: 0.9964759698624697\n",
      "User 51, CV score: 0.9919718857525736\n",
      "User 52, CV score: 0.9961214877022588\n",
      "User 53, CV score: 0.9959442376539898\n",
      "User 54, CV score: 0.994932909792508\n",
      "User 55, CV score: 0.9972370810653459\n",
      "User 56, CV score: 0.9896990003264031\n",
      "User 57, CV score: 0.9927955523430325\n",
      "User 58, CV score: 0.9965906607184805\n",
      "User 59, CV score: 0.9870507537679073\n",
      "User 60, CV score: 0.9895217638662608\n",
      "User 61, CV score: 0.9943594712746808\n",
      "User 62, CV score: 0.9902098682379454\n",
      "User 63, CV score: 0.9958087009808937\n",
      "User 64, CV score: 0.9912107870507739\n",
      "User 65, CV score: 0.997383041462272\n",
      "User 66, CV score: 0.9956835912927783\n",
      "User 67, CV score: 0.9976124204566684\n",
      "User 68, CV score: 0.9960068017379736\n",
      "User 69, CV score: 0.996569804574419\n",
      "User 70, CV score: 0.9966844943433795\n",
      "User 71, CV score: 0.9962987290541268\n",
      "User 72, CV score: 0.9972787835700174\n",
      "User 73, CV score: 0.9966532150190132\n",
      "User 74, CV score: 0.9922012669210701\n",
      "User 75, CV score: 0.9966949202413101\n",
      "User 76, CV score: 0.992472340267262\n",
      "User 77, CV score: 0.9976958232919115\n",
      "User 78, CV score: 0.9964968270935813\n",
      "User 79, CV score: 0.9965489516915079\n",
      "User 80, CV score: 0.9913150362466272\n",
      "User 81, CV score: 0.9968200359082013\n",
      "User 82, CV score: 0.9942969148000479\n",
      "User 83, CV score: 0.996204899233903\n",
      "User 84, CV score: 0.9970389819388412\n",
      "User 85, CV score: 0.9952873952138693\n",
      "User 86, CV score: 0.9970181312300305\n",
      "User 87, CV score: 0.9978834965204857\n",
      "User 88, CV score: 0.9892610990251971\n",
      "User 89, CV score: 0.9969660060885788\n",
      "User 90, CV score: 0.9954229351481156\n",
      "User 91, CV score: 0.9940571104512463\n",
      "User 92, CV score: 0.993869443744973\n",
      "User 93, CV score: 0.9845589223110972\n",
      "User 94, CV score: 0.9968408877040623\n",
      "User 95, CV score: 0.9957774238306273\n",
      "User 96, CV score: 0.9917008183851573\n",
      "User 97, CV score: 0.9893757925988332\n",
      "User 98, CV score: 0.9983422452693521\n",
      "User 99, CV score: 0.9908145920589151\n",
      "User 100, CV score: 0.9904913810701947\n",
      "User 101, CV score: 0.9942135070730792\n",
      "User 102, CV score: 0.9869673552808649\n",
      "User 103, CV score: 0.9812225654021409\n",
      "User 104, CV score: 0.9811183026181608\n",
      "User 105, CV score: 0.9916695352561152\n",
      "User 106, CV score: 0.9956940122989831\n",
      "User 107, CV score: 0.9975811443934521\n",
      "User 108, CV score: 0.9972162270953847\n",
      "User 109, CV score: 0.9977375366670845\n",
      "User 110, CV score: 0.997351767029631\n",
      "User 111, CV score: 0.9952978205682748\n",
      "User 112, CV score: 0.9971223923834354\n",
      "User 113, CV score: 0.9967157736677462\n",
      "User 114, CV score: 0.9970806871611382\n",
      "User 115, CV score: 0.9959546592037196\n",
      "User 116, CV score: 0.9965281037003224\n",
      "User 117, CV score: 0.9948077935820919\n",
      "User 118, CV score: 0.9966845024962557\n",
      "User 119, CV score: 0.996820033734101\n",
      "User 120, CV score: 0.9957669995632722\n",
      "User 121, CV score: 0.9966115119708163\n",
      "User 122, CV score: 0.9966219384122719\n",
      "User 123, CV score: 0.9969764232901082\n",
      "User 124, CV score: 0.9957774243741525\n",
      "User 125, CV score: 0.9949641885733496\n",
      "User 126, CV score: 0.9969764298124091\n",
      "User 127, CV score: 0.9982692618097385\n",
      "User 128, CV score: 0.9965489549526583\n",
      "User 129, CV score: 0.9958191252482489\n",
      "User 130, CV score: 0.9907937375454287\n",
      "User 131, CV score: 0.9934836800862952\n",
      "User 132, CV score: 0.9972370810653459\n",
      "User 133, CV score: 0.9970389851999917\n",
      "User 134, CV score: 0.9965906623490556\n",
      "User 135, CV score: 0.9978313670308333\n",
      "User 136, CV score: 0.9974038965192834\n",
      "User 137, CV score: 0.9970702612632077\n",
      "User 138, CV score: 0.9933585622453039\n",
      "User 139, CV score: 0.9950997219852951\n",
      "User 140, CV score: 0.9966219454780978\n",
      "User 141, CV score: 0.9968304569144062\n",
      "User 142, CV score: 0.9978522220878447\n",
      "User 143, CV score: 0.9957565747523918\n",
      "User 144, CV score: 0.99529782437295\n",
      "User 145, CV score: 0.997278786287643\n",
      "User 146, CV score: 0.9959859428762867\n",
      "User 147, CV score: 0.9936087914049858\n",
      "User 148, CV score: 0.99668449651748\n",
      "User 149, CV score: 0.9961736177354361\n",
      "User 150, CV score: 0.9971745213295625\n"
     ]
    }
   ],
   "source": [
    "cv_scores_by_user = {}\n",
    "for user_id in logit_cv_150users.scores_:\n",
    "    cv_scores_by_user[user_id] = logit_cv_150users.scores_[user_id].mean()\n",
    "    print('User {}, CV score: {}'.format(user_id, logit_cv_150users.scores_[user_id].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты кажутся впечатляющими, но возможно, мы забываем про дисбаланс классов, и высокую долю правильных ответов можно получить константным прогнозом. Посчитайте для каждого пользователя разницу между долей правильных ответов на кросс-валидации (только что посчитанную с помощью `LogisticRegressionCV`) и долей меток в *y_train_150*, отличных от ID \n",
    " этого пользователя (именно такую долю правильных ответов можно получить, если классификатор всегда \"говорит\", что это не пользователь с номером $i$ в задаче классификации $i$-vs-All).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distr = np.bincount(y_train_150.astype('int'))\n",
    "acc_diff_vs_constant = dict()\n",
    "\n",
    "for user_id in np.unique(y_train_150):\n",
    "    acc_diff_vs_constant[user_id] = (cv_scores_by_user[user_id] - (len(y_train_150) - class_distr[int(user_id)])/len(y_train_150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_better_than_default = (np.array(list(acc_diff_vs_constant.values())) > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 7. </font> Посчитайте долю пользователей, для которых логистическая регрессия на кросс-валидации дает прогноз лучше константного. Округлите до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer4_7.txt', 'w') as fout:\n",
    "    fout.write(f'{num_better_than_default/len(acc_diff_vs_constant):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дальше будем строить кривые обучения для конкретного пользователя, допустим, для 128-го. Составьте новый бинарный вектор на основе *y_150users*, его значения будут 1 или 0 в зависимости от того, равен ли ID-шник пользователя 128.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_binary_128 = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(val_train, val_test, train_sizes, \n",
    "                        xlabel='Training Set Size', ylabel='score'):\n",
    "    def plot_with_err(x, data, **kwargs):\n",
    "        mu, std = data.mean(1), data.std(1)\n",
    "        lines = plt.plot(x, mu, '-', **kwargs)\n",
    "        plt.fill_between(x, mu - std, mu + std, edgecolor='none',\n",
    "                         facecolor=lines[0].get_color(), alpha=0.2)\n",
    "    plot_with_err(train_sizes, val_train, label='train')\n",
    "    plot_with_err(train_sizes, val_test, label='valid')\n",
    "    plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
    "    plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посчитайте доли правильных ответов на кросс-валидации в задаче классификации \"user128-vs-All\" в зависимости от размера выборки. Не помешает посмотреть встроенную документацию для *learning_curve*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_sizes = np.linspace(0.25, 1, 20)\n",
    "estimator = svm_grid_searcher2.best_estimator_\n",
    "n_train, val_train, val_test = learning_curve ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(val_train, val_test, n_train, \n",
    "                    xlabel='train_size', ylabel='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
